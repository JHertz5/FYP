\documentclass[11pt]{article}

\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{color, soul} 	%for highlighting
\usepackage{listings} 		%for writing code
\lstset{
basicstyle=\small\ttfamily,
columns=flexible,
breaklines=true
}
\usepackage[margin=1in]{geometry} %for margins

\setcounter{page}{1}
\begin{document}

\begin{titlepage}

\title{Space Brain - Implementing a Convolutional Network on an Embedded System with an FPGA for Space Applications Suitability Testing}
\author{Jukka (Jacobus) Hertzog}
\def\supervisor{Dr. Felix Winterstein}
\def\secondmarker{Dr. David Thomas}
\def\course{EE4T}
\def\cid{00828711}

\setlength{\parindent}{0pt}
\setlength{\parskip}{0pt}
\fontfamily{phv}\selectfont
{
\large
\raggedright
Imperial College London\\[17pt]
Department of Electrical and Electronic Engineering\\[17pt]
Final Year Project Interim Report 2017\\[17pt]
}
\rule{\columnwidth}{3pt}
\vfill
\centering
\makeatletter
\begin{tabular}{p{40mm}p{\dimexpr\columnwidth-40mm}}
Project Title: & \textbf{\@title} \\[12pt]
Student: & \textbf{\@author} \\[12pt]
CID: & \textbf{\cid} \\[12pt]
Course: & \textbf{\course} \\[12pt]
Project Supervisor: & \textbf{\supervisor} \\[12pt]
Second Marker: & \textbf{\secondmarker} \\
\end{tabular}
\end{titlepage}

\section{Introduction}
\label{sec:Introduction}

Convolutional Neural Networks (CNNs) are a powerful Deep Learning tool that can be used to solve extremely complex computational problems. In particular, they have gained popularity in computer vision and image classification applications, performing with very high accuracy. However, CNNs are extremely computationally heavy. As a result, implementing them on embedded systems, which typically have very limited resources, presents many challenges. A promising solution to this problem is the use of an FPGA, which provide a very high computational power with low power usage.

Consider a miniature research satellite (a CubeSat), that uses a camera to capture images to be classified. Normally the images would be transmitted to a ground station to be processed, but in this case, channel capacity during the transmission window is too limited and the raw data is too large for this to be feasible, so the idea is to process and classify images on board the satellite and just transmit the results. Therefore, the aim of this project is to implement a CNN on an FPGA-based system, and then to investigate the suitability of this system for space applications.

\section{Project Specification}
\label{sec:ProjSpec}

\subsection{Implementation of a CNN on an FPGA}
\label{sec:ProjSpec-ImplementationOfACNNOnAnFPGA}

The first deliverable is the implementation of a CNN on an embedded platform. The hardware used is a product from Xilinx called a Zedboard, a development board for the Zynq-7000 System On a Chip (SoC). The Zynq-7000 consists of a Xilinx 28nm Artix-7 FPGA and a dual-core Cortex-A9 ARM processor integrated together. The processor, with it's easily developed code, will control the system, while the FPGA, being able to efficiently perform heavy computations, will be used to accelerate functions.

The end result will be a fully functional CNN that runs on the Zedboard and is able to process and classify images with a reasonable execution time and accuracy, compared to implementations from literature discussed in section \ref{sec:Background-CNNsImplementedOnFPGAs}. \hl{possibly different section?}

\subsection{Investigation of Fault Tolerance in the Presence of Bit-stream Corruptions}
\label{sec:ProjSpec-InvestigationOfFaultToleranceInThePresenceOfBitstreamCorruptions}

The second deliverable of this project is the invesitgation of the system's fault tolerance against SEUs. As discussed in section \ref{sec:Background-FPGAsAndSpaceApplications}, SEUs from are one of the main challenges to be overcome when using SRAM based FPGAs for applications in space. It is believed however, that the structure of a CNN may give it an inherent resistance against these SEUs. \hl{Not quite sure on this part}. The system's resistance to fault injection should indicate whether or not the system might be suitable as an on board processor for a satellite in orbit.

\section{Background}
\label{sec:Background}

\subsection{Convolutional Neural Networks}
\label{sec:Background-CNN}

A typical CNN consists of a number of layers that run in sequence. The parameters of a CNN model are called "weights". The first layer of a CNN reads an input image and outputs a series of feature maps. The following layers read the feature maps generated by previous layers and output new feature maps. Finally a classifier outputs the probability of each category that the input image might belong to. Convolution (CONV) layers and Fully Connected (FC) layers are two essential types of layer in CNN. After CONV layers, there are usually pooling layers. A typical CNN example is shown in \hl{figure QUI}.

A typical CNN is comprised of multiple convolutional layers, interspersed by normalization, pooling and activation function layers. These convolution layers decompose the input image to different features maps varying from low-level features such as edges, lines, curves, etc., in the initial layers to high-level/abstract features in the deeper layers. These extracted features are classified to output classes by fully-connected classification layers that are similar to multi-layer perceptrons. For example, Figure 1 shows the architecture of AlexNet CNN\cite{AlexNet}, which won the ImageNet challenge in 2012. It consists of 5 convolutional layers each with a Rectified Linear Unit (ReLU)
based activation function, interspersed by 2 normalization layers, 3 pooling layers and concluded by 3 fully connected layers which classify the input $224\times 224$ color images to 1,000 output classes. The ImageNet database-based models are characterized by top-1 and top-5 accuracies, which represent whether the input image label matches with top-1 and top-5 predictions, respectively.

\hl{ADD image of ALEXNET}

\subsubsection{Convolution}
\label{sec:Background-CNN-Conv}

Convolution is the most critical operation of a CNN and it constitutes over 90\% of the total operations in the AlexNet model \cite{AlexNetAgain}. It involves 3-dimensional multiply and accumulate operation of $N_if$ input features with $K\times K$ convolution filters to get an output feature neuron value as shown in Equation \ref{eq:ConvLayer}.

\begin{equation}
out(f_o,x,y)=\sum^{N_{if}}_{f_i=0} \sum^{K}_{k_x=0} \sum^{K}_{k_y=0} wt(f_o,f_i,k_x,k_y)\times in(f_i,x+k_x,y+k_y)
\label{eq:ConvLayer}
\end{equation}
where $out(f_o,x,y)$ and $in(f_i,x,y)$ represent the neurons at location $(x,y)$ in the feature maps $f_o$ and $f_i$, respectively and $wt(f_o,f_i,k_x,k_y)$ is the weights at position $(k_x,k_y)$ that gets convolved with input feature map $f_i$ to get the output feature map $f_o$.

\subsubsection{Normalisation}
\label{sec:Background-CNN-Norm}
Local Response Normalization (LRN) or normalization implements a form of lateral inhibition [16] by normalizing each neuron value by a factor that depends on the neighboring neurons. LRN across neighboring features and within the same feature can be computed as shown in Equations \ref{eq:Norm1} and \ref{eq:Norm2}, respectively.

\begin{equation}
out(f_o,x,y)= \dfrac{in(f_o,x,y)} {\left(1+\dfrac{\alpha}{K} \sum\limits^{f_o+K/2}_{f_i=f_o-K/2} {in}^2(f_i,x,y) \right) ^\beta}
\label{eq:Norm1}
\end{equation}
\begin{equation}
out(f_o,x,y)= \dfrac{in(f_o,x,y)} {\left(1+\dfrac{\alpha}{K^2} \sum\limits^{x+K/2}_{k_x=x-K/2} \sum\limits^{y+K/2}_{k_y=y-K/2} {in}^2(f_o,x+k_x,y+k_y) \right) ^\beta}
\label{eq:Norm2}
\end{equation}

where $K$ in Equation \ref{eq:Norm1} is the number of feature maps used for LRN computation, K in Equation \ref{eq:Norm2} is the number of neurons in $x, y$ directions in the same feature, while $\alpha$ and $\beta$ are constants.

\subsubsection{Pooling}
\label{sec:Background-CNN-Pool}

Spatial pooling or subsampling is utilized to reduce the feature dimensions as we traverse deeper into the network. As shown in Equation \ref{eq:Pool}, pooling computes the maximum or average of neighboring $K\times K$ neurons in the same feature map, which also provides a form of translational invariance [18]\ref{}. Although max-pooling is popularly used, average pooling is also used in some CNN models [18]\ref{}. Reducing the dimensionality of lower-level features while preserving the important information, the pooling layer helps abstracting higher-level features without redundancy.

\begin{equation}
out(f_o,x,y)=\underset{0\geqslant (k_x,k_y)<K}{max/average}(in(f_o,x+k_x,y+k_y))
\label{eq:Pool}
\end{equation}

\subsubsection{Activation Functions}
\label{sec:Background-CNN-Activation}

The commonly used activation functions in traditional neural
networks are non-linear functions such as tanh and sigmoid,
which require a longer training time in CNNs [16]. Hence,
Rectified Linear Unit (ReLU) defined as $y = max(x,0)$ has become
the popular activation function among CNN models as it
converges faster in training. Moreover, ReLU has less
computational complexity compared to exponent functions in tanh
and sigmoid, also aiding hardware design.

\subsubsection{Fully Connected Layer}
\label{sec:Background-CNN-FC}

Fully-connected layer or inner product layer is the classification layer where all the input features $(N_{if})$ are connected to all of the output features $(N_{of})$ through synaptic weights $(wt)$. Each output neuron is the weighted summation of all the input
neurons as shown in Equation \ref{eq:FullyConnected}.

\begin{equation}
out(f_o)=\sum^{N_{if}}_{f_i=0}\times in(f_i)
\label{eq:FullyConnected}
\end{equation}
The outputs of the inner-product layer traverse through
ReLU based activation function to the next inner-product layer or
directly to a Softmax function that converts them to probability in
the range (0, 1). The final accuracy layer compares the labels of
the top probabilities from softmax layer with the actual label and
gives the accuracy of the CNN model.

\subsection{CNNs Implemented on FPGAs}
\label{sec:Background-CNNsImplementedOnFPGAs}

The different layers of AlexNet are shown in Table \ref{tab:AlexNet}, along with the number of features in each layer, feature dimensions, number of synaptic weights and the total number of operations in each layer.

\subsection{FPGAs and Space Applications}
\label{sec:Background-FPGAsAndSpaceApplications}

Single Event Upsets (SEUs).

\section{Implementation Plan}
\label{sec:ImpPlan}

\subsection{Infrastrucure Setup}
\label{sec:ImpPlan-InfSetup}

This first part of the project implementation will be setting up two important tools that will be vital during the 

An important tool in this process will be Xilinx's SDSoc development environment. SDSoc is able to optimise and compile C, C++ or OpenCL source code for a Zynq system. The compiler generates software for the ARM core and, using a High Level Synthesis (HLS) tool, a bitstream for the FPGA. This allows the user to design the entire system, easily accelerating functions with the FPGA. SDSoc is a very powerful tool, facilitating the rapid development and design of firmware.

Another important tool will be Caffe (or Convolutional Architecture for Fast Feature Embedding). This is a deep learning framework that can be used to design, train, optimise and test CNNs, with a focus on computer vision\cite{jia2014caffe}. It also includes some examples of pre-trained CNN models that are ready for use. Using Caffe, it will be possible to generate C++ code for a CNN, which can then be implemented on the Zynq system using SDSoc.

\subsection{FPGA Implementation of a CNN}
\label{sec:ImpPlan-FPGAImplOfCnn}

\subsection{Fault Injection Experiments}
\label{sec:ImpPlan-FaultInjExp}

\section{Evaluation Plan}
\label{sec:EvalPlan}


These SEUs can be simulated with a process called fault injection \cite{FaultInjection}. These will 

\bibliography{interimReport_ref}
\bibliographystyle{ieeetr}
\nocite{*}


\end{document}